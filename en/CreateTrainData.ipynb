{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0df9a93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "def wntag(pttag):\n",
    "    if pttag in ['JJ', 'JJR', 'JJS','JJT']:\n",
    "        return wn.ADJ\n",
    "    elif pttag[:2] in ['NN', 'NP']:\n",
    "        return wn.NOUN\n",
    "    elif pttag in ['RB', 'RBR', 'RBS','RBT','QL']:\n",
    "        return wn.ADV\n",
    "    elif pttag[:2] in ['VB', 'DO','HV','BE','MD']:\n",
    "        return wn.VERB\n",
    "    return None\n",
    "\n",
    "def lemmatize(word,pos):\n",
    "    wnt = wntag(pos)\n",
    "    if pos[-1] == 'G' and word.endswith(\"n'\"):\n",
    "        word = word[:-1]+'g'\n",
    "    \n",
    "    if word == 'an':\n",
    "        return 'a'\n",
    "    elif word == \"n't\":\n",
    "        return 'not'\n",
    "    elif word == 'ca' and pos == 'MD':\n",
    "        return 'can'\n",
    "    elif word == \"'s'\" and pos == \"BEZ\":\n",
    "        return 'is'\n",
    "    elif word == 'men' and pos == 'NNS':\n",
    "        return 'man'\n",
    "    elif word == 'uses' and pos == 'NNS':\n",
    "        return 'use'\n",
    "    elif word == 'rated' and pos == 'VBN':\n",
    "        return 'rate'\n",
    "    elif word == 'rates' and pos == 'VBZ':\n",
    "        return 'rate'\n",
    "    elif word == 'rating' and pos == 'VBG':\n",
    "        return 'rate'\n",
    "    elif word == 'fastest':\n",
    "        return 'fast'\n",
    "    elif wnt == None:\n",
    "        return word\n",
    "    else:\n",
    "        return lemmatizer.lemmatize(word,wnt)\n",
    "\n",
    "\n",
    "def make_morphpattern(word,pos):\n",
    "    word = word.lower()\n",
    "    lemma = lemmatize(word,pos)\n",
    "    morphemes = []\n",
    "    mapping = ()\n",
    "    \n",
    "\n",
    "        \n",
    "    if lemma == word:\n",
    "        stem = word\n",
    "        suffix = ''\n",
    "    elif word == 'an' and lemma == 'a':\n",
    "        stem = word\n",
    "        suffix = ''\n",
    "    elif word.startswith(lemma+lemma[-1]):\n",
    "        stem = lemma+lemma[-1]\n",
    "        suffix = word[len(stem):]\n",
    "    elif word.startswith(lemma):\n",
    "        suffix = word[len(lemma):]\n",
    "        stem = lemma\n",
    "    elif lemma[-1] == 'e' and word.startswith(lemma[:-1]):\n",
    "        stem = lemma[:-1]\n",
    "        suffix = word[len(stem):]\n",
    "    elif word[:-3] == lemma[:-1] and lemma[-1] == 'y':\n",
    "        stem = word[:-2]\n",
    "        suffix = word[-2:]\n",
    "    elif lemma[-1] == 'f' and word.startswith(lemma[:-1]+'v'):\n",
    "        stem = lemma[:-1]+'v'\n",
    "        suffix = word[len(stem):]\n",
    "    else:\n",
    "        stem = word\n",
    "        suffix = ''\n",
    "        \n",
    "        \n",
    "    if pos == 'VBZ':\n",
    "        mtag = 'VB'\n",
    "        stag = 'SUF_VB_S'\n",
    "    elif pos == 'VBD': \n",
    "        mtag = 'VB'\n",
    "        stag = 'SUF_VB_D'\n",
    "    elif pos == 'VBN': \n",
    "        mtag = 'VB'\n",
    "        stag = 'SUF_VB_N'\n",
    "    elif pos == 'VBG':\n",
    "        mtag = 'VB'\n",
    "        stag = 'SUF_ING'\n",
    "    elif pos == 'NNS':\n",
    "        mtag = 'NN'\n",
    "        stag = 'SUF_NN_S'\n",
    "    elif pos == 'NPS':\n",
    "        mtag = 'NP'\n",
    "        stag = 'SUF_NN_S'\n",
    "    elif pos == 'JJR' or (pos == 'RBR' and suffix.endswith('er')):\n",
    "        mtag = 'JJ'\n",
    "        stag = 'SUF_JJ_R'\n",
    "    elif pos == 'JJT' or (pos == 'RBT' and suffix.endswith('st')):\n",
    "        mtag = 'JJ'\n",
    "        stag = 'SUF_JJ_T'\n",
    "    else:\n",
    "        mtag = pos\n",
    "        stag = 'SUF_'+pos\n",
    "        \n",
    "\n",
    "    if stem != lemma:\n",
    "        if len(suffix) == 0 and pos in ['VBD','VBN']:\n",
    "            mtag = mtag+'_VAR_'+pos\n",
    "        else:\n",
    "            mtag = mtag+'_VAR'\n",
    "        mapping = (mtag,stem,lemma)\n",
    "        \n",
    "        \n",
    "    morphemes.append((stem,mtag))\n",
    "    \n",
    "    if len(suffix) > 0:\n",
    "        morphemes.append((suffix,stag))\n",
    "\n",
    "    \n",
    "      \n",
    "    morphemes.append(('','END_'+pos))\n",
    "        \n",
    "    return lemma,morphemes,mapping\n",
    "\n",
    "def read_brown():\n",
    "    data = []\n",
    "    sentnr = 0\n",
    "    for sent in nltk.corpus.brown.tagged_sents():\n",
    "        sent1 = []\n",
    "        debug = False\n",
    "        problematic = False\n",
    "        \n",
    "        for (word,tag) in sent:\n",
    "            tagparts = tag.split('-')\n",
    "            tag = tagparts[0]\n",
    "            if len(tagparts) == 2:\n",
    "                TL = True\n",
    "            else:\n",
    "                TL = False\n",
    "                \n",
    "            \n",
    "            if len(tag) == 0 and word == '--':\n",
    "                sent1.append(('--','--',False)) \n",
    "            elif tag == '*':\n",
    "                sent1.append((word,'RB',TL)) \n",
    "            elif tag[-1] == '*' and word.endswith(\"n't\"):\n",
    "                sent1.append((word[:-3],tag[:-1],TL)) \n",
    "                sent1.append((\"n't\",'RB',False)) \n",
    "            elif tag == 'MD*' and word[-3:] == \"not\":\n",
    "                sent1.append((word[:-3],'MD',TL)) \n",
    "                sent1.append(('not','RB',False)) \n",
    "            elif word.endswith(\"'s\") and tag[-1] == '$':\n",
    "                sent1.append((word[:-2],tag[:-1],TL)) \n",
    "                sent1.append((\"'s\",'POS',False)) \n",
    "            elif \"'\" in word[1:] and '+' in tag:\n",
    "            #elif len(word.split(\"'\")) == 2 and len(tag.split('+')) == 2:\n",
    "                w1,w2 = word.split(\"'\")\n",
    "                t1,t2 = tag.split('+')\n",
    "                sent1.append((w1,t1,TL))\n",
    "                sent1.append((\"'\"+w2,t2,TL))\n",
    "            elif word == 'gonna' and tag == 'VBG+TO':\n",
    "                sent1.append(('gon','VBG',TL))\n",
    "                sent1.append(('na','TO',False))\n",
    "            elif word == 'gotta' and tag == 'VBG+TO':\n",
    "                sent1.append(('got','VBN',TL))\n",
    "                sent1.append(('ta','TO',False))\n",
    "            elif word[-1] == \"'\" and tag[-1] == '$':\n",
    "                sent1.append((word[:-1],tag[:-1],TL))\n",
    "                sent1.append((\"'\",'POS',False))\n",
    "            elif '+' in tag:\n",
    "                problematic = True\n",
    "            else:\n",
    "                sent1.append((word,tag,TL))\n",
    "                \n",
    "        \n",
    "        if problematic:\n",
    "            continue\n",
    "            \n",
    "        for (word,postag,TL) in sent1:\n",
    "\n",
    "            lemma,morphemes,stemsub = make_morphpattern(word,postag)\n",
    "            stem = lemma\n",
    "            if TL:\n",
    "                lemma = lemma[0].upper()+lemma[1:]\n",
    "            if len(word) and len(lemma) > 0:\n",
    "                data.append((sentnr,word,lemma,stem,postag,morphemes,stemsub))\n",
    "        sentnr += 1    \n",
    " \n",
    "    return data\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "420c1d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_morphemes(morphlist):\n",
    "\n",
    "    global adjstems \n",
    "    global verbstems\n",
    "    global vbn2morphemes\n",
    "\n",
    "    adjstems = Counter()\n",
    "    verbstems = Counter()\n",
    "    vbn2morphemes = {}\n",
    " \n",
    "    for entry in morphlist:\n",
    "        sentnr,word,lemma,stem, tag, morphemes, subst = entry\n",
    "        if tag == 'VBN':\n",
    "            vbn2morphemes[word.lower()] = morphemes[:-1]\n",
    "        for i in range(len(morphemes)):\n",
    "            m = morphemes[i]\n",
    "            if len(m[0]) < 2:\n",
    "                continue\n",
    "            elif m[1] == 'JJ' or m[1] == 'JJS':\n",
    "                adjstems.update([m[0]])\n",
    "            elif m[1] == 'VB':\n",
    "                verbstems.update([m[0]])\n",
    "            elif m[1] == 'VB_VAR':\n",
    "                verbstems.update([subst[2]])\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "726ddd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_adv(morphemes):\n",
    "    morphemes_new = []\n",
    "    mapping = ()\n",
    "    for (word,tag) in morphemes:\n",
    "        if tag in [\"RB\",\"QL\"] and word[-2:] == 'ly' and (adjstems.get(word[:-2],0) > 1 or word[:-2] in vbn2morphemes):  #honestly\n",
    "            morphemes_new.append((word[:-2],'JJ'))\n",
    "            morphemes_new.append(('ly','SUF_RB'))\n",
    "        elif tag in [\"RB\",\"QL\"]  and word[-3:] == 'ily' and adjstems.get(word[:-3]+'y',0) > 1: #easily\n",
    "            morphemes_new.append((word[:-3]+'i','JJ_VAR'))\n",
    "            morphemes_new.append(('ly','SUF_RB'))\n",
    "            mapping = ('JJ_VAR',word[:-3]+'i',word[:-3]+'y')\n",
    "        elif tag in [\"RB\",\"QL\"]  and word[-2:] == 'ly' and adjstems.get(word[:-1]+'e',0) > 1: #terribly\n",
    "            morphemes_new.append((word[:-1],'JJ_VAR'))\n",
    "            morphemes_new.append(('y','SUF_RB'))\n",
    "            mapping = ('JJ_VAR',word[:-1],word[:-1]+'e')\n",
    "        else:\n",
    "            morphemes_new.append((word,tag))\n",
    "            \n",
    "    return morphemes_new,mapping\n",
    "\n",
    "\n",
    "def split_noun(morphemes):\n",
    "    morphemes_new = []\n",
    "    mapping = ()\n",
    "    for (word,tag) in morphemes:\n",
    "        if len(word) < 8:\n",
    "            morphemes_new.append((word,tag))\n",
    "        elif tag == 'NN' and word[-4:] == 'ness' and adjstems.get(word[:-4],0) > 5:  \n",
    "            morphemes_new.append((word[:-4],'JJ'))\n",
    "            morphemes_new.append(('ness','SUF_JJN'))\n",
    "        elif tag == 'NN' and word[-5:] == 'iness' and adjstems.get(word[:-5]+'y',0) > 5: \n",
    "            morphemes_new.append((word[:-5]+'i','JJ_VAR'))\n",
    "            morphemes_new.append(('ness','SUF_JJN'))\n",
    "            mapping = ('JJ_VAR',word[:-5]+'i',word[:-5]+'y')\n",
    "        elif tag == 'NN'  and word[-3:] == 'ity' and adjstems.get(word[:-3],0) > 5: \n",
    "            morphemes_new.append((word[:-3],'JJ'))\n",
    "            morphemes_new.append(('ity','SUF_JJN'))\n",
    "        elif tag == 'NN_VAR'  and word[-3:] == 'iti' and adjstems.get(word[:-3],0) > 5: \n",
    "            morphemes_new.append((word[:-3],'JJ'))\n",
    "            morphemes_new.append(('iti','SUF_JJN_VAR'))\n",
    "            mapping = ('SUF_JJN_VAR','iti','ity')\n",
    "        elif tag == 'NN'  and word[-3:] == 'ity' and adjstems.get(word[:-3]+'e',0) > 5: \n",
    "            morphemes_new.append((word[:-3],'JJ_VAR'))\n",
    "            morphemes_new.append(('ity','SUF_JJN'))\n",
    "            mapping = ('JJ_VAR',word[:-3],word[:-3]+'e')\n",
    "        elif tag == 'NN_VAR'  and word[-3:] == 'iti' and adjstems.get(word[:-3]+'e',0) > 5: \n",
    "            morphemes_new.append((word[:-3],'JJ_VAR'))\n",
    "            morphemes_new.append(('iti','SUF_JJN_VAR'))\n",
    "            mapping = ('SUF_JJN_VAR','iti','ity')\n",
    "            #mapping = ('JJ_VAR',word[:-3],word[:-3]+'e')\n",
    "        else:\n",
    "            morphemes_new.append((word,tag))\n",
    "            \n",
    "    return morphemes_new,mapping\n",
    "\n",
    "\n",
    "def split_adj(morphemes):\n",
    "    morphemes_new = []\n",
    "    mapping = ()\n",
    "    \n",
    "    word,tag = morphemes[0]\n",
    "    if word.startswith('un') and  (adjstems.get(word[2:],0) > 0 or (not word.startswith('under') and not word.startswith('uni') and not word.startswith('unanim')  )):\n",
    "        morphemes = [('un','PREF_NEG'),(word[2:],tag)] + morphemes[1:]\n",
    "        #print(morphemes)\n",
    "    \n",
    "    for (word,tag) in morphemes:\n",
    "        if tag == 'JJ' and word.endswith('ing') and verbstems.get(word[:-3],0) > 1:  \n",
    "            morphemes_new.append((word[:-3],'VB'))\n",
    "            morphemes_new.append(('ing','SUF_ING'))\n",
    "        elif tag == 'JJ' and word.endswith('ing') and verbstems.get(word[:-3]+'e',0) > 1:  \n",
    "            morphemes_new.append((word[:-3]+'e','VB'))\n",
    "            morphemes_new.append(('ing','SUF_ING'))\n",
    "            mapping = ('VB_VAR',word[:-3],word[:-3]+'e') \n",
    "        elif tag == 'JJ' and word in vbn2morphemes:\n",
    "            morphemes_new.extend(vbn2morphemes[word])\n",
    "        elif len(word) < 8:\n",
    "            morphemes_new.append((word,tag))\n",
    "        elif tag == 'JJ' and word[-4:] == 'able' and verbstems.get(word[:-4],0) > 5:  \n",
    "            morphemes_new.append((word[:-4],'VB'))\n",
    "            morphemes_new.append(('able','SUF_VBJJ'))\n",
    "        elif tag == 'JJ' and word[-4:] == 'able' and verbstems.get(word[:-4]+'e',0) > 5:  \n",
    "            morphemes_new.append((word[:-4],'VB_VAR'))\n",
    "            morphemes_new.append(('able','SUF_VBJJ'))\n",
    "        elif tag == 'JJ' and word[-5:] == 'iable' and verbstems.get(word[:-5]+'y',0) > 5:  \n",
    "            morphemes_new.append((word[:-5]+'i','VB_VAR'))\n",
    "            morphemes_new.append(('able','SUF_VBJJ'))\n",
    "        elif tag == 'JJ_VAR' and word[-3:] == 'abl' and verbstems.get(word[:-3],0) > 5:  \n",
    "            morphemes_new.append((word[:-3],'VB'))\n",
    "            morphemes_new.append(('abl','SUF_VBJJ'))\n",
    "        elif tag == 'JJ+VAR' and word[-3:] == 'able' and verbstems.get(word[:-3]+'e',0) > 5:  \n",
    "            morphemes_new.append((word[:-3],'VB_VAR'))\n",
    "            morphemes_new.append(('abl','SUF_VBJJ'))\n",
    "        elif tag == 'JJ_VAR' and word[-3:] == 'iabl' and verbstems.get(word[:-4]+'y',0) > 5:  \n",
    "            morphemes_new.append((word[:-3]+'i','VB_VAR'))\n",
    "            morphemes_new.append(('able','SUF_VBJJ'))\n",
    "\n",
    "        else:\n",
    "            morphemes_new.append((word,tag))\n",
    "            \n",
    "    return morphemes_new,mapping\n",
    "\n",
    "def postprocess_morphemes(morphlist):\n",
    "    data = []\n",
    "    \n",
    "    for entry in morphlist:\n",
    "        if len(entry) != 7:\n",
    "            data.append(entry)\n",
    "            continue\n",
    "        sentnr,word,lemma,stem, tag, morphemes, subst = entry\n",
    "        if tag in [\"RB\",\"QL\"]:\n",
    "            morphemes_new, subst_new = split_adv(morphemes)\n",
    "            if len(subst_new) >= len(subst):\n",
    "                subst = subst_new\n",
    "            morphemes_new, _ = split_adj(morphemes_new)\n",
    "            #morphemes_new, subst_new = split_adj(morphemes_new)\n",
    "            #if len(subst_new) > len(subst):\n",
    "            #    subst = subst_new\n",
    "        elif tag in [\"NNS\",\"NN\"]:    \n",
    "            morphemes_new, subst_new = split_noun(morphemes)\n",
    "            if len(subst_new) >= len(subst):\n",
    "                subst = subst_new\n",
    "        elif tag == 'JJ':    \n",
    "            morphemes_new, subst_new = split_adj(morphemes)\n",
    "            if len(subst_new) >= len(subst):\n",
    "                subst = subst_new\n",
    "        else:\n",
    "            morphemes_new = morphemes\n",
    "        data.append((sentnr,word,lemma,stem, tag, morphemes_new, subst))\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7025bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = read_brown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7d89cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_morphemes(Data)\n",
    "Data = postprocess_morphemes(Data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d98f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "fout = codecs.open(\"labeledmorph_en.csv\", \"w\",\"utf-8\")\n",
    "\n",
    "for word in Data:\n",
    "    print(*word,sep='\\t',end='\\n',file=fout)\n",
    "fout.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d66c4908",
   "metadata": {},
   "outputs": [],
   "source": [
    "##https://gist.github.com/nschneid/6476715\n",
    "#http://korpus.uib.no/icame/manuals/BROWN/INDEX.HTM#bc6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
